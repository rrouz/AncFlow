Building DAG of jobs...
Retrieving input from storage.
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job stats:
job                  count
-----------------  -------
rename_tree_file         1
subtree_extractor        1
total                    2

Select jobs to execute...
Execute 1 jobs...

[Tue Feb 13 02:48:44 2024]
localrule rename_tree_file:
    input: logs/autophy_success.txt
    output: output/autophy_tree.nwk
    jobid: 1
    reason: Missing output files: output/autophy_tree.nwk
    resources: tmpdir=/var/folders/6w/cbbj2d4d1cs82bbv3lr2jt700000gn/T

[Tue Feb 13 02:48:48 2024]
Finished job 1.
1 of 2 steps (50%) done
Select jobs to execute...
Execute 1 jobs...

[Tue Feb 13 02:48:48 2024]
localrule subtree_extractor:
    input: output/autophy_tree.nwk
    output: logs/extraction_success.txt
    jobid: 0
    reason: Missing output files: logs/extraction_success.txt; Input files updated by another job: output/autophy_tree.nwk
    resources: tmpdir=/var/folders/6w/cbbj2d4d1cs82bbv3lr2jt700000gn/T

[Tue Feb 13 02:50:38 2024]
Finished job 0.
2 of 2 steps (100%) done
Complete log: .snakemake/log/2024-02-13T024843.016908.snakemake.log
